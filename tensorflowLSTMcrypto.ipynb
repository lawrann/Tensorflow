{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict future crypto price using LSTM sequence on close and volume. This is binary classification\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"crypto_data/LTC-USD.csv\", names=['time', 'low', 'high', 'open', 'close', 'volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas DataFrame is two-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes \n",
    "# (rows and columns). A Data frame is a two-dimensional data structure, \n",
    "# i.e., data is aligned in a tabular fashion in rows and columns. Pandas DataFrame consists of three principal \n",
    "# components, the data, rows, and columns.\n",
    "main_df = pd.DataFrame() # begin empty\n",
    "\n",
    "# We want to combine each of the csv file for the crypto currency together into the empty pandas datafram\n",
    "ratios = [\"BTC-USD\", \"LTC-USD\", \"BCH-USD\", \"ETH-USD\"]  # the 4 ratios we want to consider\n",
    "for ratio in ratios:  # begin iteration\n",
    "    #print(ratio)\n",
    "    dataset = f'crypto_data/{ratio}.csv'  # get the full path to the file.\n",
    "    df = pd.read_csv(dataset, names=['time', 'low', 'high', 'open', 'close', 'volume'])  # read in specific file\n",
    "\n",
    "    # rename volume and close to include the ticker so we can still distinguish which close/volume is which for each csv:\n",
    "    df.rename(columns={\"close\": f\"{ratio}_close\", \"volume\": f\"{ratio}_volume\"}, inplace=True) \\\n",
    "    # inplace = True, data is renamed in place, replace nothing\n",
    "    # inplace = False, df2 = df.rename(..., inplace=False)\n",
    "    # when ^ inplace is false, result is assigned to a new variable\n",
    "\n",
    "    # set time column as index so we can join them on this shared time\n",
    "    df.set_index(\"time\", inplace=True)  \n",
    "    df = df[[f\"{ratio}_close\", f\"{ratio}_volume\"]]  # ignore the other columns besides closing price and volume\n",
    "\n",
    "    # merging of all the csvs\n",
    "    if len(main_df)==0:  # if the dataframe is empty\n",
    "        main_df = df  # then it's just the current df\n",
    "    else:  # otherwise, join this data to the main one\n",
    "        main_df = main_df.join(df)\n",
    "\n",
    "main_df.fillna(method=\"ffill\", inplace=True)  # if there are gaps in data, use previously known values\n",
    "main_df.dropna(inplace=True)\n",
    "#print(main_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a target (how far out we want to predict)\n",
    "# if we have a sequence length of 3 (3 minutes of historical data), cant predict 10 minutes in the future\n",
    "# if we have sequence length of 300, 10 might be predictable\n",
    "# we will go with sequence length of 60 and future prediction, target, of 3\n",
    "\n",
    "SEQ_LEN = 60  # how long of a preceeding sequence to collect for RNN\n",
    "FUTURE_PERIOD_PREDICT = 3  # how far into the future are we trying to predict?\n",
    "RATIO_TO_PREDICT = \"BCH-USD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function takes future and current value. 1 if future>current, 0 otherwise\n",
    "# Train network based on these, 1 is good, price increase in future, 0 is bad. (Binary classification)\n",
    "def classify(current, future):\n",
    "    if float(future) > float(current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# future_period_predict is 3\n",
    "# A .shift will just shift the columns for us, a negative shift will shift them \"up.\" \n",
    "# So shifting up 3 will give us the price 3 minutes in the future, and we're just assigning this to a new column.\n",
    "# This creates a future column based on the 3 rows forward (future price)\n",
    "main_df['future'] = main_df[f'{RATIO_TO_PREDICT}_close'].shift(-FUTURE_PERIOD_PREDICT)\n",
    "\n",
    "# The map() is used to map a function. \n",
    "# The first parameter here is the function we want to map (classify),\n",
    "# then the next ones are the parameters to that function. \n",
    "# In this case, the current close price, and then the future price.\n",
    "# The map part is what allows us to do this row-by-row for these columns, \n",
    "# but also do it quite fast. The list part converts the end result to a list, which we can just set as a column.\n",
    "# target is a binary column of 1 increase in future price, 0 decrease in future price\n",
    "main_df['target'] = list(map(classify, main_df[f'{RATIO_TO_PREDICT}_close'], main_df['future']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            BCH-USD_close      future  target\n",
      "time                                         \n",
      "1528968720     870.859985  870.000000       0\n",
      "1528968780     870.099976  869.989990       0\n",
      "1528968840     870.789978  869.450012       0\n",
      "1528968900     870.000000  869.989990       0\n",
      "1528968960     869.989990  870.000000       1\n",
      "1528969020     869.450012  870.320007       1\n",
      "1528969080     869.989990  870.650024       1\n",
      "1528969140     870.000000  871.219971       1\n",
      "1528969200     870.320007  871.880005       1\n",
      "1528969260     870.650024  871.880005       1\n"
     ]
    }
   ],
   "source": [
    "print(main_df[[f\"{RATIO_TO_PREDICT}_close\",\"future\",\"target\"]].head(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 9\n",
    "# for sequence / lstm / timeseries prediction, do not shuffle data and slice it to training and testing sets\n",
    "# this will cause overfitting, just slice the data into train n test set in its order. Take the last 5% as test set\n",
    "times = sorted(main_df.index.values)  # get the times\n",
    "last_5pct = sorted(main_df.index.values)[-int(0.05*len(times))]  # get the last 5% in time index\n",
    "\n",
    "validation_main_df = main_df[(main_df.index >= last_5pct)]  # make the validation data where the index is in the last 5%\n",
    "main_df = main_df[(main_df.index < last_5pct)]  # now the main_df is all the data up to the last 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize n balance data\n",
    "# balance - make sure the classes have equal amounts when training (use class weights)\n",
    "\n",
    "from sklearn import preprocessing  \n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_df(df):\n",
    "    df = df.drop(\"future\", 1)  # don't need this anymore, was only needed to create the target (actual output label)\n",
    "\n",
    "    for col in df.columns:  # go through all of the columns\n",
    "        if col != \"target\":  # normalize all ... except for the target itself!\n",
    "            df[col] = df[col].pct_change()  # pct change \"normalizes\" the different currencies (each crypto coin has vastly diff values, we're really more interested in the other coin's movements)\n",
    "            df.dropna(inplace=True)  # remove the nas created by pct_change\n",
    "            df[col] = preprocessing.scale(df[col].values)  # scale between 0 and 1.\n",
    "    df.dropna(inplace=True)  # cleanup again... jic.\n",
    "    \n",
    "    sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "    prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "\n",
    "    for i in df.values:  # iterate over the values\n",
    "        # n for n means each column within the row, currently contains  => btc close, btc volume, ltc close, ltc volume, ..., target\n",
    "        # think of it as n1 for n2 - each n1(column) within the n2(row)\n",
    "        # in i[:-1] => this is to remove the last column target. You dont want target inside.\n",
    "        # [:-1] means up to the last i, means we are not taking target\n",
    "        prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "        if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])  # append those 60 feature set and target label (X and y)!\n",
    "\n",
    "    random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "    \n",
    "    # part 10\n",
    "    # now we gonna balance the list, so that we have even target 0 and 1\n",
    "    buys = []  # list that will store our buy sequences and targets\n",
    "    sells = []  # list that will store our sell sequences and targets\n",
    "\n",
    "    for seq, target in sequential_data:  # iterate over the sequential data\n",
    "        if target == 0:  # if it's a \"not buy\"\n",
    "            sells.append([seq, target])  # append to sells list\n",
    "        elif target == 1:  # otherwise if the target is a 1...\n",
    "            buys.append([seq, target])  # it's a buy!\n",
    "\n",
    "    random.shuffle(buys)  # shuffle the buys\n",
    "    random.shuffle(sells)  # shuffle the sells!\n",
    "\n",
    "    lower = min(len(buys), len(sells))  # what's the shorter length?\n",
    "\n",
    "    buys = buys[:lower]  # make sure both lists are only up to the shortest length.\n",
    "    sells = sells[:lower]  # make sure both lists are only up to the shortest length.\n",
    "\n",
    "    sequential_data = buys+sells  # add them together\n",
    "    random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for seq, target in sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "\n",
    "    return np.array(X), y  # return X and y...and make X a numpy array! ..import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 79532 validation: 3606\n",
      "Dont buys: 39766, buys: 39766\n",
      "VALIDATION Dont buys: 1803, buys: 1803\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = preprocess_df(main_df)\n",
    "validation_x, validation_y = preprocess_df(validation_main_df)\n",
    "\n",
    "print(f\"train data: {len(train_x)} validation: {len(validation_x)}\")\n",
    "print(f\"Dont buys: {train_y.count(0)}, buys: {train_y.count(1)}\")\n",
    "print(f\"VALIDATION Dont buys: {validation_y.count(0)}, buys: {validation_y.count(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Part 11\n",
    "# Building the model\n",
    "import time\n",
    "\n",
    "EPOCHS = 10  # how many passes through our data\n",
    "BATCH_SIZE = 64  # how many batches? Try smaller batch if you're getting OOM (out of memory) errors.\n",
    "NAME = f\"{RATIO_TO_PREDICT}-{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\"  # a unique name for the model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "# modelcheckpoint allows the saving of the best epoch, so u can revert back if model is overfitted or something like that\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "# general use case is to use BN between the linear and non-linear layers in your network, \n",
    "# because it normalizes the input to your activation function, so that you're centered in the linear section of \n",
    "# the activation function (such as Sigmoid).\n",
    "# https://www.reddit.com/r/MachineLearning/comments/2x0bq8/some_questions_regarding_batch_normalization/?su=ynbwk&st=iprg6e3w&sh=88bcbe40\n",
    "model.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n",
    "\n",
    "model.add(LSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128, input_shape=(train_x.shape[1:])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=\"logs\\{}\".format(NAME))\n",
    "filepath = \"RNN_Final-{epoch:02d}-{val_acc:.3f}\"  # unique file name that will include the epoch and the validation acc for that epoch\n",
    "checkpoint = ModelCheckpoint(\"models\\{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')) # saves only the best ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0723 07:02:15.675613 19276 deprecation.py:323] From C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79532 samples, validate on 3606 samples\n",
      "Epoch 1/10\n",
      "   64/79532 [..............................] - ETA: 40:15 - loss: 0.8463 - accuracy: 0.4844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0723 07:02:23.917753 19276 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.951948). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79532/79532 [==============================] - 266s 3ms/sample - loss: 0.7030 - accuracy: 0.5417 - val_loss: 0.6886 - val_accuracy: 0.5291\n",
      "Epoch 2/10\n",
      "79532/79532 [==============================] - 239s 3ms/sample - loss: 0.6794 - accuracy: 0.5689 - val_loss: 0.6694 - val_accuracy: 0.5899\n",
      "Epoch 3/10\n",
      "79532/79532 [==============================] - 242s 3ms/sample - loss: 0.6752 - accuracy: 0.5794 - val_loss: 0.6705 - val_accuracy: 0.5871\n",
      "Epoch 4/10\n",
      "79532/79532 [==============================] - 237s 3ms/sample - loss: 0.6730 - accuracy: 0.5828 - val_loss: 0.6744 - val_accuracy: 0.5727\n",
      "Epoch 5/10\n",
      "79532/79532 [==============================] - 241s 3ms/sample - loss: 0.6718 - accuracy: 0.5878 - val_loss: 0.6695 - val_accuracy: 0.5918\n",
      "Epoch 6/10\n",
      "79532/79532 [==============================] - 236s 3ms/sample - loss: 0.6698 - accuracy: 0.5889 - val_loss: 0.6750 - val_accuracy: 0.5729\n",
      "Epoch 7/10\n",
      "79532/79532 [==============================] - 235s 3ms/sample - loss: 0.6673 - accuracy: 0.5931 - val_loss: 0.6752 - val_accuracy: 0.5854\n",
      "Epoch 8/10\n",
      "79532/79532 [==============================] - 234s 3ms/sample - loss: 0.6646 - accuracy: 0.6002 - val_loss: 0.6754 - val_accuracy: 0.5874\n",
      "Epoch 9/10\n",
      "79532/79532 [==============================] - 235s 3ms/sample - loss: 0.6596 - accuracy: 0.6057 - val_loss: 0.6869 - val_accuracy: 0.5788\n",
      "Epoch 10/10\n",
      "79532/79532 [==============================] - 234s 3ms/sample - loss: 0.6531 - accuracy: 0.6139 - val_loss: 0.6815 - val_accuracy: 0.5793\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_x, validation_y),\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 1188), started 21:41:53 ago. (Use '!kill 1188' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0723 07:44:17.360505 19276 manager.py:321] invalid info file: 'C:\\\\Users\\\\Lawrann\\\\AppData\\\\Local\\\\Temp\\\\.tensorboard-info\\\\pid-16176.info'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 316, in get_all\n",
      "    info = _info_from_string(contents)\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 155, in _info_from_string\n",
      "    raise ValueError(\"incompatible version: %r\" % (json_value,))\n",
      "ValueError: incompatible version: {'cache_key': 'eyJhcmd1bWVudHMiOlsiLS1sb2dkaXIiLCJsb2dzIl0sImNvbmZpZ3VyZV9rd2FyZ3MiOnt9LCJ3b3JraW5nX2RpcmVjdG9yeSI6IkM6XFxVc2Vyc1xcTGF3cmFublxcdGVuc29yZmxvd05OIn0=', 'db': '', 'logdir': 'logs', 'path_prefix': '', 'pid': 16176, 'port': 6006, 'start_time': 1563760101, 'version': '1.14.0'}\n",
      "W0723 07:44:17.368484 19276 manager.py:321] invalid info file: 'C:\\\\Users\\\\Lawrann\\\\AppData\\\\Local\\\\Temp\\\\.tensorboard-info\\\\pid-2084.info'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 316, in get_all\n",
      "    info = _info_from_string(contents)\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 155, in _info_from_string\n",
      "    raise ValueError(\"incompatible version: %r\" % (json_value,))\n",
      "ValueError: incompatible version: {'cache_key': 'eyJhcmd1bWVudHMiOlsiLS1sb2dkaXIiLCJ7QzpcXFVzZXJzXFxMYXdyYW5uXFx0ZW5zb3JmbG93Tk5cXGxvZ3N9Il0sImNvbmZpZ3VyZV9rd2FyZ3MiOnt9LCJ3b3JraW5nX2RpcmVjdG9yeSI6IkM6XFxVc2Vyc1xcTGF3cmFublxcdGVuc29yZmxvd05OIn0=', 'db': '', 'logdir': '{C:\\\\Users\\\\Lawrann\\\\tensorflowNN\\\\logs}', 'path_prefix': '', 'pid': 2084, 'port': 6006, 'start_time': 1563760386, 'version': '1.14.0'}\n",
      "W0723 07:44:17.374469 19276 manager.py:321] invalid info file: 'C:\\\\Users\\\\Lawrann\\\\AppData\\\\Local\\\\Temp\\\\.tensorboard-info\\\\pid-22660.info'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 316, in get_all\n",
      "    info = _info_from_string(contents)\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 155, in _info_from_string\n",
      "    raise ValueError(\"incompatible version: %r\" % (json_value,))\n",
      "ValueError: incompatible version: {'cache_key': 'eyJhcmd1bWVudHMiOlsiLS1sb2dkaXIiLCJ7QzpcXFVzZXJzXFxMYXdyYW5uXFx0ZW5zb3JmbG93Tk5cXGxvZ3N9Il0sImNvbmZpZ3VyZV9rd2FyZ3MiOnt9LCJ3b3JraW5nX2RpcmVjdG9yeSI6IkM6XFxVc2Vyc1xcTGF3cmFublxcdGVuc29yZmxvd05OIn0=', 'db': '', 'logdir': '{C:\\\\Users\\\\Lawrann\\\\tensorflowNN\\\\logs}', 'path_prefix': '', 'pid': 22660, 'port': 6006, 'start_time': 1563760324, 'version': '1.14.0'}\n",
      "W0723 07:44:17.383445 19276 manager.py:321] invalid info file: 'C:\\\\Users\\\\Lawrann\\\\AppData\\\\Local\\\\Temp\\\\.tensorboard-info\\\\pid-24780.info'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 316, in get_all\n",
      "    info = _info_from_string(contents)\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 155, in _info_from_string\n",
      "    raise ValueError(\"incompatible version: %r\" % (json_value,))\n",
      "ValueError: incompatible version: {'cache_key': 'eyJhcmd1bWVudHMiOlsiLS1sb2dkaXIiLCJDOlVzZXJzTGF3cmFubnRlbnNvcmZsb3dOTmxvZ3MiXSwiY29uZmlndXJlX2t3YXJncyI6e30sIndvcmtpbmdfZGlyZWN0b3J5IjoiQzpcXFVzZXJzXFxMYXdyYW5uXFx0ZW5zb3JmbG93Tk4ifQ==', 'db': '', 'logdir': 'C:UsersLawranntensorflowNNlogs', 'path_prefix': '', 'pid': 24780, 'port': 6006, 'start_time': 1563760168, 'version': '1.14.0'}\n",
      "W0723 07:44:17.398411 19276 manager.py:321] invalid info file: 'C:\\\\Users\\\\Lawrann\\\\AppData\\\\Local\\\\Temp\\\\.tensorboard-info\\\\pid-708.info'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 316, in get_all\n",
      "    info = _info_from_string(contents)\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 155, in _info_from_string\n",
      "    raise ValueError(\"incompatible version: %r\" % (json_value,))\n",
      "ValueError: incompatible version: {'cache_key': 'eyJhcmd1bWVudHMiOlsiLS1sb2dkaXIiLCJ7QzpVc2Vyc0xhd3Jhbm50ZW5zb3JmbG93Tk5sb2dzfSJdLCJjb25maWd1cmVfa3dhcmdzIjp7fSwid29ya2luZ19kaXJlY3RvcnkiOiJDOlxcVXNlcnNcXExhd3Jhbm5cXHRlbnNvcmZsb3dOTiJ9', 'db': '', 'logdir': '{C:UsersLawranntensorflowNNlogs}', 'path_prefix': '', 'pid': 708, 'port': 6006, 'start_time': 1563760256, 'version': '1.14.0'}\n",
      "W0723 07:44:17.407379 19276 manager.py:321] invalid info file: 'C:\\\\Users\\\\Lawrann\\\\AppData\\\\Local\\\\Temp\\\\.tensorboard-info\\\\pid-7568.info'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 316, in get_all\n",
      "    info = _info_from_string(contents)\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 155, in _info_from_string\n",
      "    raise ValueError(\"incompatible version: %r\" % (json_value,))\n",
      "ValueError: incompatible version: {'cache_key': 'eyJhcmd1bWVudHMiOlsiLS1sb2dkaXIiLCJ7QzpcXFVzZXJzXFxMYXdyYW5uXFx0ZW5zb3JmbG93Tk5cXGxvZ3N9Il0sImNvbmZpZ3VyZV9rd2FyZ3MiOnt9LCJ3b3JraW5nX2RpcmVjdG9yeSI6IkM6XFxVc2Vyc1xcTGF3cmFublxcdGVuc29yZmxvd05OIn0=', 'db': '', 'logdir': '{C:\\\\Users\\\\Lawrann\\\\tensorflowNN\\\\logs}', 'path_prefix': '', 'pid': 7568, 'port': 6006, 'start_time': 1563759773, 'version': '1.14.0'}\n",
      "W0723 07:44:17.412370 19276 manager.py:321] invalid info file: 'C:\\\\Users\\\\Lawrann\\\\AppData\\\\Local\\\\Temp\\\\.tensorboard-info\\\\pid-16176.info'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 316, in get_all\n",
      "    info = _info_from_string(contents)\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 155, in _info_from_string\n",
      "    raise ValueError(\"incompatible version: %r\" % (json_value,))\n",
      "ValueError: incompatible version: {'cache_key': 'eyJhcmd1bWVudHMiOlsiLS1sb2dkaXIiLCJsb2dzIl0sImNvbmZpZ3VyZV9rd2FyZ3MiOnt9LCJ3b3JraW5nX2RpcmVjdG9yeSI6IkM6XFxVc2Vyc1xcTGF3cmFublxcdGVuc29yZmxvd05OIn0=', 'db': '', 'logdir': 'logs', 'path_prefix': '', 'pid': 16176, 'port': 6006, 'start_time': 1563760101, 'version': '1.14.0'}\n",
      "W0723 07:44:17.414362 19276 manager.py:321] invalid info file: 'C:\\\\Users\\\\Lawrann\\\\AppData\\\\Local\\\\Temp\\\\.tensorboard-info\\\\pid-2084.info'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 316, in get_all\n",
      "    info = _info_from_string(contents)\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 155, in _info_from_string\n",
      "    raise ValueError(\"incompatible version: %r\" % (json_value,))\n",
      "ValueError: incompatible version: {'cache_key': 'eyJhcmd1bWVudHMiOlsiLS1sb2dkaXIiLCJ7QzpcXFVzZXJzXFxMYXdyYW5uXFx0ZW5zb3JmbG93Tk5cXGxvZ3N9Il0sImNvbmZpZ3VyZV9rd2FyZ3MiOnt9LCJ3b3JraW5nX2RpcmVjdG9yeSI6IkM6XFxVc2Vyc1xcTGF3cmFublxcdGVuc29yZmxvd05OIn0=', 'db': '', 'logdir': '{C:\\\\Users\\\\Lawrann\\\\tensorflowNN\\\\logs}', 'path_prefix': '', 'pid': 2084, 'port': 6006, 'start_time': 1563760386, 'version': '1.14.0'}\n",
      "W0723 07:44:17.417356 19276 manager.py:321] invalid info file: 'C:\\\\Users\\\\Lawrann\\\\AppData\\\\Local\\\\Temp\\\\.tensorboard-info\\\\pid-22660.info'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 316, in get_all\n",
      "    info = _info_from_string(contents)\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 155, in _info_from_string\n",
      "    raise ValueError(\"incompatible version: %r\" % (json_value,))\n",
      "ValueError: incompatible version: {'cache_key': 'eyJhcmd1bWVudHMiOlsiLS1sb2dkaXIiLCJ7QzpcXFVzZXJzXFxMYXdyYW5uXFx0ZW5zb3JmbG93Tk5cXGxvZ3N9Il0sImNvbmZpZ3VyZV9rd2FyZ3MiOnt9LCJ3b3JraW5nX2RpcmVjdG9yeSI6IkM6XFxVc2Vyc1xcTGF3cmFublxcdGVuc29yZmxvd05OIn0=', 'db': '', 'logdir': '{C:\\\\Users\\\\Lawrann\\\\tensorflowNN\\\\logs}', 'path_prefix': '', 'pid': 22660, 'port': 6006, 'start_time': 1563760324, 'version': '1.14.0'}\n",
      "W0723 07:44:17.418352 19276 manager.py:321] invalid info file: 'C:\\\\Users\\\\Lawrann\\\\AppData\\\\Local\\\\Temp\\\\.tensorboard-info\\\\pid-24780.info'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 316, in get_all\n",
      "    info = _info_from_string(contents)\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 155, in _info_from_string\n",
      "    raise ValueError(\"incompatible version: %r\" % (json_value,))\n",
      "ValueError: incompatible version: {'cache_key': 'eyJhcmd1bWVudHMiOlsiLS1sb2dkaXIiLCJDOlVzZXJzTGF3cmFubnRlbnNvcmZsb3dOTmxvZ3MiXSwiY29uZmlndXJlX2t3YXJncyI6e30sIndvcmtpbmdfZGlyZWN0b3J5IjoiQzpcXFVzZXJzXFxMYXdyYW5uXFx0ZW5zb3JmbG93Tk4ifQ==', 'db': '', 'logdir': 'C:UsersLawranntensorflowNNlogs', 'path_prefix': '', 'pid': 24780, 'port': 6006, 'start_time': 1563760168, 'version': '1.14.0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0723 07:44:17.421343 19276 manager.py:321] invalid info file: 'C:\\\\Users\\\\Lawrann\\\\AppData\\\\Local\\\\Temp\\\\.tensorboard-info\\\\pid-708.info'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 316, in get_all\n",
      "    info = _info_from_string(contents)\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 155, in _info_from_string\n",
      "    raise ValueError(\"incompatible version: %r\" % (json_value,))\n",
      "ValueError: incompatible version: {'cache_key': 'eyJhcmd1bWVudHMiOlsiLS1sb2dkaXIiLCJ7QzpVc2Vyc0xhd3Jhbm50ZW5zb3JmbG93Tk5sb2dzfSJdLCJjb25maWd1cmVfa3dhcmdzIjp7fSwid29ya2luZ19kaXJlY3RvcnkiOiJDOlxcVXNlcnNcXExhd3Jhbm5cXHRlbnNvcmZsb3dOTiJ9', 'db': '', 'logdir': '{C:UsersLawranntensorflowNNlogs}', 'path_prefix': '', 'pid': 708, 'port': 6006, 'start_time': 1563760256, 'version': '1.14.0'}\n",
      "W0723 07:44:17.423341 19276 manager.py:321] invalid info file: 'C:\\\\Users\\\\Lawrann\\\\AppData\\\\Local\\\\Temp\\\\.tensorboard-info\\\\pid-7568.info'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 316, in get_all\n",
      "    info = _info_from_string(contents)\n",
      "  File \"C:\\Users\\Lawrann\\Anaconda3\\lib\\site-packages\\tensorboard\\manager.py\", line 155, in _info_from_string\n",
      "    raise ValueError(\"incompatible version: %r\" % (json_value,))\n",
      "ValueError: incompatible version: {'cache_key': 'eyJhcmd1bWVudHMiOlsiLS1sb2dkaXIiLCJ7QzpcXFVzZXJzXFxMYXdyYW5uXFx0ZW5zb3JmbG93Tk5cXGxvZ3N9Il0sImNvbmZpZ3VyZV9rd2FyZ3MiOnt9LCJ3b3JraW5nX2RpcmVjdG9yeSI6IkM6XFxVc2Vyc1xcTGF3cmFublxcdGVuc29yZmxvd05OIn0=', 'db': '', 'logdir': '{C:\\\\Users\\\\Lawrann\\\\tensorflowNN\\\\logs}', 'path_prefix': '', 'pid': 7568, 'port': 6006, 'start_time': 1563759773, 'version': '1.14.0'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x182627cf198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load TENSORBOARD\n",
    "%load_ext tensorboard\n",
    "# Start TENSORBOARD\n",
    "%tensorboard --logdir=C:\\Users\\Lawrann\\tensorflowNN\\logs\n",
    "# if running through cmd prompt, must be at C:\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
